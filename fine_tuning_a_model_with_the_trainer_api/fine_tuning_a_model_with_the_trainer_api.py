import numpy as np
import evaluate
import torch
import torch.nn.functional as F  # Potrzebne do funkcji Softmax (zamiana surowych wynikÃ³w na %)
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
    EarlyStoppingCallback,
)
import wandb

import os

os.environ['WANDB_API_KEY'] = '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'

# ==============================================================================
# 1. PRZYGOTOWANIE DANYCH I POJÄ˜Ä† (FILOZOFIA PRE-TRAININGU)
# ==============================================================================
checkpoint = "bert-base-uncased"
print(f"\n[1/6] Pobieranie modelu i danych: {checkpoint}...")

# DATASET: ZbiÃ³r par zdaÅ„. LABEL (Etykieta) to wynik: 1 (parafraza), 0 (rÃ³Å¼ne).
# Oryginalny BERT od Google uczyÅ‚ siÄ™ na 3.3 mld sÅ‚Ã³w (Wikipedia + KsiÄ…Å¼ki).
# On juÅ¼ "rozumie" jÄ™zyk, ale nie wie jeszcze, co to jest zadanie "MRPC".
raw_datasets = load_dataset("glue", "mrpc")

# TOKENIZER: Pobiera "SÅ‚ownik" (Vocab) przypisany do modelu.
# Zamienia sÅ‚owa na numery ID. SkÄ…d wie jakie numery? KaÅ¼dy model ma swÃ³j
# unikalny plik .txt ze sÅ‚ownikiem. Tutaj tekst staje siÄ™ matematykÄ….
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

def tokenize_function(example):
    # --- ETAP PRZYGOTOWANIA PALIWA DLA MODELU ---
    # Tokenizer nie posiada jeszcze "GÅ‚Ã³w Uwagi" (Heads), ale przygotowuje dane
    # w taki sposÃ³b, aby 144 gÅ‚owy wewnÄ…trz BERT-a wiedziaÅ‚y, co robiÄ‡:

    # 1. INPUT_IDS: Zamienia sÅ‚owa na liczby.
    #    KaÅ¼dy numer to klucz do wielowymiarowego wektora znaczeniowego (Embedding).

    # 2. [CLS] (Classification Token): Dodaje specjalny token na samym poczÄ…tku.
    #    To "stacja zbiorcza" â€“ model po przejÅ›ciu przez wszystkie 144 gÅ‚owy uwagi
    #    skupi caÅ‚Ä… wiedzÄ™ o relacji miÄ™dzy zdaniami wÅ‚aÅ›nie w tym jednym miejscu.
    #    Nasza "GÅ‚owica Klasyfikacyjna" (num_labels=2) patrzy TYLKO na ten token.

    # 3. [SEP] (Separator Token): Wstawia znacznik miÄ™dzy zdanie A i B.
    #    DziÄ™ki temu mechanizm Attention wie, gdzie koÅ„czy siÄ™ kontekst jednego zdania.

    # 4. TOKEN_TYPE_IDS (Segment Embeddings): Tworzy maskÄ™ (0 dla zdania A, 1 dla B).
    #    To "podpowiedÅº" dla modelu, ktÃ³ra pozwala mu fizycznie odrÃ³Å¼niÄ‡ od siebie dwa teksty.

    # 5. ATTENTION MASK: Tworzy mapÄ™ (1 dla tekstu, 0 dla paddingu).
    #    MÃ³wi gÅ‚owom uwagi: "Skup siÄ™ na 1, ignoruj 0 (puste miejsca)".

    # 6. TRUNCATION: Bezpiecznik. JeÅ›li suma tokenÃ³w zdania A i B > 512,
    #    obetnie koÅ„cÃ³wkÄ™, by nie przekroczyÄ‡ fizycznej pamiÄ™ci warstw Attention.
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)

print("\n[2/6] Tokenizacja (zamiana sÅ‚Ã³w na numery ID)...")
tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

# EPOKA (Epoch): Przeczytanie caÅ‚ej "ksiÄ…Å¼ki" (zbioru danych) jeden raz.
# Epoch 1.0 oznacza, Å¼e model przejrzaÅ‚ wszystkie przykÅ‚ady dokÅ‚adnie raz.

# --- KLUCZOWE ROZRÃ“Å»NIENIE: TRAIN VS VALIDATION ---
# Dlaczego dzielimy dane? WyobraÅº sobie, Å¼e uczysz siÄ™ do egzaminu z matematyki.

# 1. ZbiÃ³r TRENINGOWY (train): To Twoje ZADANIA DOMOWE.
# Tu model widzi zarÃ³wno pytania, jak i poprawne odpowiedzi. Na ich podstawie model
# krÄ™ci swoimi "pokrÄ™tÅ‚ami" (wagami), Å¼eby zminimalizowaÄ‡ bÅ‚Ä…d.
# KIEDY UÅ»YWAMY: Zawsze podczas fazy wÅ‚aÅ›ciwego uczenia (trainer.train()).
tokenized_datasets["train"] = tokenized_datasets["train"].shuffle(seed=42).select(range(200))

# 2. ZbiÃ³r WALIDACYJNY (validation): To TwÃ³j EGZAMIN PRÃ“BNY.
# Model dostaje pytania, ale NIE widzi odpowiedzi podczas "rozwiÄ…zywania". My sprawdzamy
# jego odpowiedzi dopiero po fakcie. Model NIGDY nie poprawia swoich wag na podstawie
# tego zbioru â€“ on sÅ‚uÅ¼y tylko nam, Å¼eby sprawdziÄ‡, czy model siÄ™ uczy zasad, czy tylko
# kuje przykÅ‚ady na pamiÄ™Ä‡.
# KIEDY UÅ»YWAMY: Podczas treningu, zazwyczaj po kaÅ¼dej epoce, Å¼eby monitorowaÄ‡ postÄ™py.
# DLACZEGO TO POTRZEBNE? Bez walidacji nie wiedzielibyÅ›my, czy model nie wpada w
# OVERFITTING (przeuczenie). To sytuacja, w ktÃ³rej model na zadaniach domowych ma 100%
# skutecznoÅ›ci, ale na nowym pytaniu, ktÃ³rego wczeÅ›niej nie widziaÅ‚, caÅ‚kowicie polega.
tokenized_datasets["validation"] = tokenized_datasets["validation"].select(range(50))

# DATA COLLATOR: WyrÃ³wnuje dÅ‚ugoÅ›Ä‡ zdaÅ„ w paczce (batchu) dodajÄ…c zera (padding).
# Modele wymagajÄ…, aby dane w jednej paczce (batch) miaÅ‚y identyczny wymiar.
# DYNAMIC PADDING: Zmniejsza obciÄ…Å¼enie obliczeniowe poprzez dopeÅ‚nianie tylko do
# maksymalnej dÅ‚ugoÅ›ci w obrÄ™bie kaÅ¼dej partii (batch), a nie caÅ‚ego zbioru (np. 512).
# Kluczowe dla szybkoÅ›ci na procesorze Ultra 7 - nie marnujemy cykli na przetwarzanie zer.
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# ==============================================================================
# 2. ARCHITEKTURA: WARSTWY (PIÄ˜TRA), HEADY (OCZY) I GÅOWICA KLASYFIKATORA
# ==============================================================================
print("\n[3/6] Åadowanie modelu i instalacja nowej 'GÅ‚owicy' klasyfikatora...")

# KLUCZOWY MOMENT: Odcinamy oryginalnÄ… gÅ‚owÄ™ BERT-a (tÄ™ do przewidywania sÅ‚Ã³w)
# i "przyszywamy" nowÄ…, klasyfikacyjnÄ… gÅ‚owÄ™ z 2 wyjÅ›ciami (TAK/NIE).
#
# TRANSFER LEARNING: Nie uczysz modelu angielskiego od zera. Wykorzystujesz "wiedzÄ™ ogÃ³lnÄ…"
# bert-base-uncased i dodajesz do niej nowÄ… warstwÄ™ (Linear Layer),
# ktÃ³ra uczy siÄ™ wyÅ‚Ä…cznie specyfiki zadania MRPC (rozpoznawanie parafraz).
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

# --- CZYM JEST 12 WARSTW (LAYERS) W BERT-BASE? (PIONOWA HIERARCHIA) ---
# WyobraÅº sobie model jako 12-piÄ™trowy wieÅ¼owiec. Dane wchodzÄ… na parterze i jadÄ… windÄ… do gÃ³ry.
# KaÅ¼da warstwa (piÄ™tro) przetwarza tekst na coraz wyÅ¼szym poziomie abstrakcji:
#
# 1. WARSTWY DOLNE (1-4): "LingwiÅ›ci Lokalni"
#    AnalizujÄ… proste, fizyczne relacje miÄ™dzy literami i sÅ‚owami. SkupiajÄ… siÄ™ na tym,
#    jak sÄ…siadujÄ…ce sÅ‚owa wpÅ‚ywajÄ… na siebie (np. czy "is" pasuje do "Pawel").
#    BudujÄ… fundament gramatyczny i rozpoznajÄ… proste struktury skÅ‚adniowe.
#
# 2. WARSTWY ÅšRODKOWE (5-8): "ÅÄ…cznicy Kontekstu"
#    ZaczynajÄ… rozumieÄ‡ szerszy sens. Tu model zauwaÅ¼a zaleÅ¼noÅ›ci na poziomie caÅ‚ych
#    fraz. Rozpoznaje czÄ™Å›ci mowy i rozumie, Å¼e zaimek "on" odnosi siÄ™ do osoby
#    wymienionej trzy sÅ‚owa wczeÅ›niej. To etap budowania "mapy powiÄ…zaÅ„".
#
# 3. WARSTWY GÃ“RNE (9-12): "Filozofowie Znaczenia"
#    Tutaj dzieje siÄ™ magia czystej semantyki. Te warstwy nie analizujÄ… juÅ¼ liter,
#    ale czyste koncepcje (idee). RozumiejÄ…, Å¼e "here" i "present" w tej konkretnej
#    parze zdaÅ„ oznaczajÄ… to samo. To te warstwy wysyÅ‚ajÄ… raport do tokena [CLS].
#
# DLACZEGO JEST ICH AÅ» 12?
# Bo zrozumienie jÄ™zyka jest hierarchiczne. Nie da siÄ™ zrozumieÄ‡ ironii (poziom 12)
# bez zrozumienia znaczenia sÅ‚owa (poziom 1). KaÅ¼da warstwa korzysta z wynikÃ³w
# pracy warstwy poprzedniej, coraz bardziej "wyÅ¼ymajÄ…c" esencjÄ™ ze zdaÅ„.

# --- CZYM SÄ„ HEADY (GÅOWY UWAGI)? (POZIOMA SPECJALIZACJA) ---
# UWAGA: Warstwy to NIE to samo co Heady! Heady pracujÄ… WEWNÄ„TRZ kaÅ¼dej warstwy.
# Na kaÅ¼dym z 12 piÄ™ter (warstw) pracuje 12 wyspecjalizowanych pracownikÃ³w (GÅ‚Ã³w).
# ÅÄ…cznie masz 144 "mikro-mÃ³zgi" (12 warstw x 12 gÅ‚Ã³w).
#
# DLACZEGO JEST ICH 12 NA KAÅ»DYM PIÄ˜TRZE?
# Zamiast jednego pracownika, ktÃ³ry patrzy na wszystko, masz 12 detektywÃ³w:
# Jeden pilnuje gramatyki, drugi szuka synonimÃ³w, trzeci patrzy na interpunkcjÄ™,
# a jeszcze inny sprawdza emocje. PracujÄ… rÃ³wnolegle, dajÄ…c modelowi 12 rÃ³Å¼nych
# perspektyw na to samo sÅ‚owo w tym samym czasie.

# --- JAK DZIAÅAJÄ„ HEADY? (MECHANIZM Q, K, V) ---
# KaÅ¼da gÅ‚owa dla kaÅ¼dego sÅ‚owa tworzy trzy wektory (matematyczne reprezentacje):
# 1. QUERY (Q) - "Zapytanie": SÅ‚owo 'here' wysyÅ‚a zapytanie: "Szukam sÅ‚Ã³w o miejscu".
# 2. KEY (K) - "Klucz": SÅ‚owo 'present' ma klucz, ktÃ³ry pasuje: "Ja opisujÄ™ obecnoÅ›Ä‡".
# 3. VALUE (V) - "WartoÅ›Ä‡": Skoro Q i K do siebie pasujÄ…, gÅ‚owa pobiera 'wartoÅ›Ä‡'
#    (znaczenie) ze sÅ‚owa 'present' i aktualizuje nim wektor sÅ‚owa 'here'.
# Wynik tej "rozmowy" miÄ™dzy sÅ‚owami pÅ‚ynie w gÃ³rÄ™ do kolejnej warstwy.

# --- WAGI (WEIGHTS) I TRENING ---
# WAGI: To miliony "pokrÄ™teÅ‚" (liczb) wewnÄ…trz modelu. Trening to krÄ™cenie nimi.
# KaÅ¼da waga decyduje, jak mocno dany sygnaÅ‚ (np. informacja z konkretnej gÅ‚owy
# w 10. warstwie) wpÅ‚ywa na wynik koÅ„cowy.
#
# Wagi w "mÃ³zgu" (warstwy Attention) sÄ… juÅ¼ ustawione przez Google na podstawie
# miliardÃ³w zdaÅ„, ale w Twojej nowej "GÅ‚owicy Klasyfikacyjnej" sÄ… na razie
# caÅ‚kowicie LOSOWE â€“ to dlatego przed treningiem model zgaduje wynik na 50%.
weights_before = model.classifier.weight.data[0][:5].clone()
print(f"ğŸ‘‰ Wagi nowej gÅ‚owy PRZED treningiem (losowe): {weights_before}")

# ==============================================================================
# 3. TEST MODELU PRZED TRENINGIEM (Zgadujemy!)
# ==============================================================================
print("\n[3.5] TEST PRZED TRENINGIEM (Logity i Softmax):")
# Wyzwanie dla synonimÃ³w: czy model "poczuje" podobieÅ„stwo bez nauki?
z1 = "Pawel is here"
z2 = "Pawel is present"

# Przygotowanie danych do rÄ™cznego testu matematycznego
inputs = tokenizer(z1, z2, return_tensors="pt")

# torch.inference_mode() â€“ Jeszcze szybszy tryb "tylko do odczytu" niÅ¼ no_grad.
# CaÅ‚kowicie izoluje model od mechanizmÃ³w treningowych dla maksymalnej wydajnoÅ›ci CPU.

with torch.inference_mode():
    outputs_pre = model(**inputs)
    # LOGITY: Surowe punkty z modelu (np. [-1.2, 0.5]). Nie sumujÄ… siÄ™ do 100%.
    # SÄ… to surowe wyniki zwracane przez ostatniÄ… warstwÄ™ modelu przed Softmaxem.
    logits_pre = outputs_pre.logits

# SOFTMAX: Funkcja, ktÃ³ra zamienia surowe punkty (logity) na procenty (0-100%).
# W matematyce: przeksztaÅ‚ca wektor liczb na wektor prawdopodobieÅ„stw, ktÃ³re sumujÄ… siÄ™ do 1.
probs_pre = F.softmax(logits_pre, dim=-1)
print(f"ğŸ‘‰ Zdanie A: {z1} | Zdanie B: {z2}")
print(f"ğŸ‘‰ Surowe logity PRZED naukÄ…: {logits_pre}")
print(f"ğŸ‘‰ PewnoÅ›Ä‡ PRZED naukÄ… (Softmax): {probs_pre[0][1].item():.2%}")

# ==============================================================================
# 4. METRYKI, GRADIENTY I LOSS (Zasady oceniania)
# ==============================================================================

# Pobieramy gotowy "arkusz ocen" poza funkcjÄ…, aby uniknÄ…Ä‡ przeÅ‚adowywania go.
metric = evaluate.load("glue", "mrpc")


# TA FUNKCJA TO "EGZAMINATOR". OkreÅ›la, jak model bÄ™dzie oceniany podczas nauki.
def compute_metrics(eval_preds):
    # EWALUACJA (Evaluation): Aby oceniÄ‡ wydajnoÅ›Ä‡ modelu w sposÃ³b zrozumiaÅ‚y dla czÅ‚owieka,
    # potrzebujemy metryk, a nie tylko samej straty (loss).

    # eval_preds to paczka zawierajÄ…ca:
    # 1. Logity (co model "myÅ›li" - surowe liczby)
    # 2. Labels (jaka jest prawda - etykiety 0/1)
    logits, labels = eval_preds

    # LOSS (Strata): Matematyczna miara bÅ‚Ä™du. JeÅ›li spada, model lepiej rozumie dane.
    # WyobraÅº sobie Loss jako odlegÅ‚oÅ›Ä‡ od celu â€“ im mniejszy Loss, tym bliÅ¼ej jesteÅ›my prawdy.
    # Na poczÄ…tku treningu Loss moÅ¼e byÄ‡ wysoki (np. ok. 0.7-0.9).
    # PowinieneÅ› zobaczyÄ‡ jego spadek z kaÅ¼dym krokiem (logging step).

    # GRADIENT: Instrukcja, w ktÃ³rÄ… stronÄ™ krÄ™ciÄ‡ wagÄ…, aby LOSS malaÅ‚.
    # Gradient to matematyczna "strzaÅ‚ka" mÃ³wiÄ…ca: "Zmniejsz tÄ™ wagÄ™ o 0.01, aby byÄ‡ bliÅ¼ej wyniku".
    # GRAD_NORM: SiÅ‚a tej instrukcji (im wiÄ™kszy, tym gwaÅ‚towniejsza zmiana wag).

    # PREDICTIONS: To ostateczny "strzaÅ‚" modelu (odpowiedÅº na egzaminie).
    # Wybieramy indeks (0 lub 1), ktÃ³ry otrzymaÅ‚ najwiÄ™cej punktÃ³w w logitach.
    # ARGMAX: Wybieramy indeks o najwyÅ¼szej wartoÅ›ci dla kaÅ¼dej prÃ³bki,
    # aby przeksztaÅ‚ciÄ‡ logity w konkretne klasy (0 lub 1).
    # PrzykÅ‚ad: jeÅ›li logity to [-2.5, 3.1], argmax wybierze indeks "1" (klasa pozytywna).
    predictions = np.argmax(logits, axis=-1)

    # LABELS: To "klucz odpowiedzi" (prawdziwe etykiety ze zbioru danych).
    # Nauczyciel (metric) porÃ³wnuje predictions z labels.
    # Wynik to sÅ‚ownik zawierajÄ…cy Accuracy (dokÅ‚adnoÅ›Ä‡) oraz F1 Score (Å›rednia precyzji i peÅ‚noÅ›ci).
    # Accuracy mÃ³wi: "Ile razy trafiÅ‚eÅ›?". F1 mÃ³wi: "Jak dobrze radzisz sobie z obiema klasami?".
    # W zadaniu MRPC metryka F1 jest waÅ¼niejsza niÅ¼ samo Accuracy, poniewaÅ¼ zbiory te bywajÄ… niezbalansowane.

    # --- INTERPRETACJA METRYK W CZASIE RZECZYWISTYM ---
    # JeÅ›li Accuracy roÅ›nie wolniej niÅ¼ spada Loss, to znaczy, Å¼e model staje siÄ™
    # pewniejszy swoich decyzji, ale jeszcze nie na tyle, by zmieniÄ‡ klasyfikacjÄ™ bÅ‚Ä™dnych przykÅ‚adÃ³w.
    return metric.compute(predictions=predictions, references=labels)


# ==============================================================================
# 5. KONFIGURACJA TRENINGU (Zoptymalizowana pod Intel Ultra 7 + Zaawansowane funkcje)
# ==============================================================================
# TrainingArguments to "centrum sterowania" procesem nauki. To tutaj decydujemy o strategii.

# Inicjalizacja Weights & Biases do Å›ledzenia eksperymentÃ³w
wandb.init(project="transformer-fine-tuning", name="bert-mrpc-analysis-huggingface-trainer-api")

training_args = TrainingArguments(
    output_dir="./test-trainer-cpu",
    # UÅ¼ywamy CPU, bo GPU zawiesza laptopa przy obliczeniach AI.
    use_cpu=True,

    # --- ZAAWANSOWANE FUNKCJE TRENINGOWE (ADVANCED FEATURES) ---

    # EVALUATION STRATEGY: Pozwala kontrolowaÄ‡ czÄ™stotliwoÅ›Ä‡ przeprowadzania testÃ³w.
    # "epoch" oznacza sprawdzian (eval) po kaÅ¼dej peÅ‚nej epoce (przeczytaniu caÅ‚ych danych).
    # DziÄ™ki temu po kaÅ¼dej epoce zobaczymy, czy model staje siÄ™ mÄ…drzejszy.
    # ANALIZA: JeÅ›li Validation Loss zacznie rosnÄ…Ä‡ po 2. epoce, mimo Å¼e Train Loss spada,
    # mamy do czynienia z przeuczeniem (Overfitting).
    eval_strategy="epoch",
    # SAVE STRATEGY: Musi byÄ‡ identyczna jak eval_strategy, gdy uÅ¼ywamy load_best_model_at_end.
    # DziÄ™ki temu Trainer po kaÅ¼dym sprawdzianie (epoch) zapisze wagi modelu na dysku,
    # co pozwoli mu na samym koÅ„cu wrÃ³ciÄ‡ do tej wersji, ktÃ³ra miaÅ‚a najlepsze wyniki.
    save_strategy="epoch",

    # LEARNING RATE SCHEDULER: Model domyÅ›lnie zmniejsza "dÅ‚ugoÅ›Ä‡ kroku" (LR) wraz z treningiem.
    # "cosine" (kosinusoidalny) to zaawansowany sposÃ³b: najpierw model uczy siÄ™ szybko,
    # a potem coraz delikatniej "cyzeluje" wagi, co zapobiega psuciu wynikÃ³w na koniec.
    # Metafora: Na poczÄ…tku biegniesz w stronÄ™ celu, a na koÅ„cu robisz maÅ‚e, precyzyjne kroczki.
    lr_scheduler_type="cosine",

    # MIXED PRECISION (fp16): Pozwala na obliczenia na liczbach 16-bitowych zamiast 32-bitowych.
    # UWAGA: Na CPU zazwyczaj zostawiamy False, ale na nowszych GPU ustawienie fp16=True
    # dramatycznie przyspiesza trening i oszczÄ™dza poÅ‚owÄ™ pamiÄ™ci VRAM.
    # Mniejsza precyzja (mniej cyfr po przecinku) pozwala "upchnÄ…Ä‡" wiÄ™cej obliczeÅ„ naraz.
    fp16=False,

    # GRADIENT ACCUMULATION: Technika dla osÃ³b z maÅ‚Ä… iloÅ›ciÄ… pamiÄ™ci.
    # JeÅ›li ustawisz gradient_accumulation_steps=4 i batch_size=4, model zachowa siÄ™ tak,
    # jakby trenowaÅ‚ na paczce o rozmiarze 16, ale "pogryzie" jÄ… na mniejsze kawaÅ‚ki po 4.
    # DziÄ™ki temu oszczÄ™dzamy pamiÄ™Ä‡ RAM, symulujÄ…c pracÄ™ na potÄ™Å¼nym sprzÄ™cie.
    gradient_accumulation_steps=1,

    num_train_epochs=3,  # Model przeczyta 200 zdaÅ„ 3 razy (lepsza stabilnoÅ›Ä‡).
    # LEARNING_RATE: To "pewnoÅ›Ä‡ siebie" modelu. 2e-5 to bardzo maÅ‚a wartoÅ›Ä‡ (0.00002).
    # MaÅ‚e kroki zapobiegajÄ… "przeskoczeniu" idealnego ustawienia wag (tzw. overshooting).
    # JeÅ›li krzywa straty na W&B jest bardzo "poszarpana", warto zmniejszyÄ‡ tÄ™ wartoÅ›Ä‡.
    learning_rate=2e-5,  # "DÅ‚ugoÅ›Ä‡ kroku" (jak mocno gradient zmienia wagi).

    per_device_train_batch_size=4,  # Wykorzystujemy 14 rdzeni Twojego procesora.
    # ANALIZA BATCHA: WiÄ™kszy batch size (np. 16, 32) daje gÅ‚adsze krzywe uczenia,
    # bo kierunek zmian wag jest uÅ›redniany z wiÄ™kszej liczby przykÅ‚adÃ³w.

    weight_decay=0.01,  # "Hamulec": zapobiega przypisywaniu ogromnych wag sÅ‚owom.
    # WEIGHT DECAY to kara za zbyt duÅ¼e wagi. Zapobiega sytuacji, w ktÃ³rej model skupia siÄ™
    # obsesyjnie na jednym sÅ‚owie (np. "the") ignorujÄ…c resztÄ™ kontekstu.
    logging_steps=5,  # Co 5 paczek wypisz stan w konsoli.
    report_to="wandb",  # WysyÅ‚anie logÃ³w do Weights & Biases
    load_best_model_at_end=True,  # ZaÅ‚aduj najlepszy model na koÅ„cu (ten z najniÅ¼szym Validation Loss).
)

# ==============================================================================
# 6. TWORZENIE TRAINERA (DYRYGENT PROCESU)
# ==============================================================================
# Trainer Å‚Ä…czy model, dane, parametry i metryki w jednÄ… maszynÄ™ treningowÄ….
# WyobraÅº sobie Trainera jako dyrygenta orkiestry â€“ pilnuje, aby dane pÅ‚ynÄ™Å‚y do modelu,
# metryki byÅ‚y liczone, a wagi aktualizowane w odpowiednim momencie.
trainer = Trainer(
    model=model,  # Nasz BERT z nowÄ… gÅ‚owicÄ….
    args=training_args,  # Wszystkie ustawienia z punktu 5.
    train_dataset=tokenized_datasets["train"],  # MateriaÅ‚y do nauki.
    eval_dataset=tokenized_datasets["validation"],  # MateriaÅ‚y do sprawdzianu.
    data_collator=data_collator,  # Maszyna do wyrÃ³wnywania dÅ‚ugoÅ›ci zdaÅ„ (padding).
    processing_class=tokenizer,  # Nasz tÅ‚umacz tekstu na liczby.
    compute_metrics=compute_metrics,  # Nasz egzaminator z punktu 4.

    # EARLY STOPPING CALLBACK: Mechanizm bezpieczeÅ„stwa.
    # JeÅ›li przez 3 sprawdziany (patience=3) model nie poprawi wyniku na zbiorze walidacyjnym,
    # Trainer przerwie naukÄ™, chroniÄ…c model przed "wykuciem danych na blachÄ™" (Overfitting).
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
)

# ==============================================================================
# 7. TRENING I ANALIZA ZMIAN W "MÃ“ZGU"
# ==============================================================================
print("\n[4/6] Start Fine-tuningu (Trening nowej gÅ‚owy na Intel Ultra 7)...")
# LOSS (Strata) powinna spadaÄ‡ z kaÅ¼dym krokiem.
# Podczas trainer.train() model wykonuje pÄ™tlÄ™ treningowÄ…:
# 1. Przekazuje dane przez model (Forward pass) - "Czytanie pytania"
# 2. Oblicza bÅ‚Ä…d (Loss) - "Sprawdzanie bÅ‚Ä™du"
# 3. Oblicza gradienty (Backward pass) - "Szukanie przyczyny bÅ‚Ä™du"
# 4. Aktualizuje pokrÄ™tÅ‚a (Optimizer step) - "Poprawa wiedzy (zmiana wag)"

# --- JAK INTERPRETOWAÄ† LOGI W TRAKCIE? ---
# JeÅ›li "Training Loss" spada, a "Validation Loss" stoi w miejscu lub roÅ›nie:
# Oznacza to, Å¼e model traci zdolnoÅ›Ä‡ generalizacji. Ciesz siÄ™ wtedy, Å¼e masz EarlyStopping!
trainer.train()

print("\n[5/6] Sprawdzanie zmian w 'mÃ³zgu' modelu...")
weights_after = model.classifier.weight.data[0][:5].clone()
print(f"ğŸ‘‰ Wagi przed: {weights_before}")
print(f"ğŸ‘‰ Wagi po:    {weights_after}")

# --- DLACZEGO LICZYMY 'diff' I CO TO MA DO ZNACZENIA? ---
# WyobraÅº sobie, Å¼e waga (weight) to "siÅ‚a zaufania" do danej cechy:
# 1. Model przed naukÄ… ma losowe zaufanie (np. ufa literze 'X' w szukaniu synonimÃ³w).
# 2. Podczas treningu model zauwaÅ¼a: "Zaraz, litera 'X' nic mi nie mÃ³wi o parafrazie,
#    ale wektor z 10. warstwy (ten od synonimÃ³w) jest mega waÅ¼ny!".
# 3. Model "przesuwa" wagÄ™ (liczbÄ™) z cechy nieistotnej na istotnÄ….
#
# ZWIÄ„ZEK Z TRENINGIEM:
# Te liczby w 'diff' to Å›lad po tym, co model widziaÅ‚ w tych 200 zdaniach.
# JeÅ›li 'diff' jest wyraÅºne, to znaczy, Å¼e te 200 zdaÅ„ daÅ‚o modelowi "lekcjÄ™",
# ktÃ³ra kazaÅ‚a mu zmieniÄ‡ zdanie o tym, co jest waÅ¼ne.
#
# TO NIE JEST PORÃ“WNANIE ZDAÅƒ - TO BILANS ZYSKÃ“W I STRAT WIEDZY.
# Wynik 'diff' mÃ³wi nam: "O tyle model staÅ‚ siÄ™ inny po przeczytaniu ksiÄ…Å¼ki".

diff = weights_after - weights_before

# DLACZEGO TO JEST WAÅ»NE DLA POCZÄ„TKUJÄ„CEGO?
# JeÅ›li 'diff' wynosiÅ‚oby same zera, oznaczaÅ‚oby to, Å¼e model niczego siÄ™ nie nauczyÅ‚
# (np. Learning Rate byÅ‚ za maÅ‚y lub dane byÅ‚y bÅ‚Ä™dne).
# KaÅ¼da liczba rÃ³Å¼na od zera w 'diff' to dowÃ³d na to, Å¼e model "Å¼yje" i reaguje na dane.
# DuÅ¼e wartoÅ›ci w 'diff' mogÄ… sugerowaÄ‡, Å¼e model gwaÅ‚townie zmieniaÅ‚ zdanie (niestabilny trening).
print(f"ğŸ‘‰ RÃ³Å¼nica (fizyczny efekt nauki): {diff}")

# ==============================================================================
# 8. TEST PRAKTYCZNY PO TRENINGU (WERYFIKACJA "NOWYCH NAWYKÃ“W" MODELU)
# ==============================================================================
print("\n[6/6] TEST PO TRENINGU (Analiza synonimÃ³w):")

# torch.inference_mode() â€“ WyÅ‚Ä…czamy "tryb nauki".
# MÃ³wimy modelowi: "Teraz nie masz nic zmieniaÄ‡ w wagach, po prostu uÅ¼yj tego,
# czego siÄ™ przed chwilÄ… nauczyÅ‚eÅ›". To oszczÄ™dza RAM i przyspiesza dziaÅ‚anie.
with torch.inference_mode():
    # FORWARD PASS: Przepuszczamy nasze testowe zdania ("Pawel is here/present")
    # przez odÅ›wieÅ¼onÄ… architekturÄ™. Teraz kaÅ¼da ze 144 gÅ‚Ã³w uwagi (Heads)
    # wysyÅ‚a sygnaÅ‚ do nowo ustawionej GÅ‚owicy Klasyfikacyjnej.
    outputs_post = model(**inputs)

    # LOGITY: To surowe punkty (np. [-2.5, 4.1]).
    # To jest moment, w ktÃ³rym model "krzyczy" wynik na podstawie swoich nowych wag.
    # WyÅ¼sza liczba na drugim miejscu (indeks 1) oznacza: "Tak, to parafraza!".
    logits_post = outputs_post.logits

    # SOFTMAX: Zamiana surowej siÅ‚y gÅ‚osu na cywilizowane procenty.
    # Ta funkcja bierze logity i rozdziela je tak, by suma obu wynosiÅ‚a 100%.
    # PrzykÅ‚adowo: logity [-2, 4] zmieniÄ… siÄ™ w [0.2%, 99.8%].
    probs_post = F.softmax(logits_post, dim=-1)

    # CONFIDENCE: WyciÄ…gamy konkretnÄ… liczbÄ™ dla klasy "Parafraza" (indeks 1).
    # .item() zamienia obiekt PyTorch (tensor) na zwykÅ‚Ä… liczbÄ™ typu float w Pythonie.
    confidence = probs_post[0][1].item()

# --- DLACZEGO TO JEST MOMENT "PRAWDY"? ---
# 1. Przed naukÄ…: GÅ‚owica miaÅ‚a losowe wagi, wiÄ™c wynik Softmax byÅ‚ bliski 50% (rzut monetÄ…).
# 2. Po nauce: GÅ‚owica "wie", Å¼e sygnaÅ‚y o synonimach z Heads sÄ… waÅ¼ne.
#    Dlatego logity dla klasy 1 powinny byÄ‡ teraz znacznie wyÅ¼sze.
#
# ANALIZA: JeÅ›li pewnoÅ›Ä‡ (Confidence) wzrosÅ‚a, np. z 52% na 88%, TwÃ³j fine-tuning
# odniÃ³sÅ‚ sukces â€“ model fizycznie "zrozumiaÅ‚" intencjÄ™ Twojego zadania.

# ZMIANA PEWNOÅšCI: Twoje testowe zdania ("Pawel is here" vs "Pawel is present")
# powinny po treningu uzyskaÄ‡ znacznie wyÅ¼szy wynik procentowy w klasie 1 (parafraza),
# o ile 200 przykÅ‚adÃ³w wystarczy, by model "zrozumiaÅ‚" intencjÄ™ zadania.
print(f"ğŸ‘‰ Zdanie A: {z1} | Zdanie B: {z2}")
print(f"ğŸ‘‰ Wynik PRZED naukÄ…: {probs_pre[0][1].item():.2%}")
print(f"ğŸ‘‰ Wynik PO nauce:    {confidence:.2%}")

# --- ANALIZA TECHNICZNA DLA KOLEGI (WHY THIS MATTERS) ---
# 1. SEMANTIC SIMILARITY: Model musiaÅ‚ wykazaÄ‡ siÄ™ wiedzÄ… z pre-trainingu,
#    Å¼eby wiedzieÄ‡, Å¼e "here" i "present" to w tym kontekÅ›cie synonimy.
#
# 2. ROLE OF ATTENTION: Twoje 144 gÅ‚owy uwagi analizujÄ… kontekst sÅ‚owa "Pawel".
#    W obu zdaniach Pawel peÅ‚ni tÄ™ samÄ… rolÄ™ (podmiot), co pomaga modelowi.
#
# 3. CPU EFFICIENCY: Trening trwaÅ‚ krÃ³tko, bo TwÃ³j Ultra 7 Å›wietnie
#    radzi sobie z matematykÄ… macierzowÄ… dziÄ™ki instrukcjom AVX/AMX.

# ==============================================================================
# 9. ZAPISYWANIE MODELU NA DYSKU
# ==============================================================================
# Zapisujemy wagi modelu i sÅ‚ownik tokenizera do folderu.
trainer.save_model("./fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy")
tokenizer.save_pretrained("./fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy")
print("\nModel zapisany w './fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy'!")