import numpy as np
import evaluate
import torch
import torch.nn.functional as F  # Potrzebne do funkcji Softmax (zamiana surowych wynikÃ³w na %)
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)

# ==============================================================================
# 1. PRZYGOTOWANIE DANYCH I POJÄ˜Ä† (FILOZOFIA PRE-TRAININGU)
# ==============================================================================
checkpoint = "bert-base-uncased"
print(f"\n[1/6] Pobieranie modelu i danych: {checkpoint}...")

# DATASET: ZbiÃ³r par zdaÅ„. LABEL (Etykieta) to wynik: 1 (parafraza), 0 (rÃ³Å¼ne).
# Oryginalny BERT od Google uczyÅ‚ siÄ™ na 3.3 mld sÅ‚Ã³w (Wikipedia + KsiÄ…Å¼ki).
# On juÅ¼ "rozumie" jÄ™zyk, ale nie wie jeszcze, co to jest zadanie "MRPC".
raw_datasets = load_dataset("glue", "mrpc")

# TOKENIZER: Pobiera "SÅ‚ownik" (Vocab) przypisany do modelu.
# Zamienia sÅ‚owa na numery ID. SkÄ…d wie jakie numery? KaÅ¼dy model ma swÃ³j
# unikalny plik .txt ze sÅ‚ownikiem. Tutaj tekst staje siÄ™ matematykÄ….
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

def tokenize_function(example):
    # ATTENTION HEADS (GÅ‚owy Uwagi): WewnÄ…trz modelu jest 12 warstw, a kaÅ¼da ma 12 gÅ‚Ã³w.
    # Razem 144 "mikro-mÃ³zgi", ktÃ³re analizujÄ… tekst pod rÃ³Å¼nymi kÄ…tami.
    # ÅÄ…czymy dwa zdania. Tokenizer doda [CLS] na poczÄ…tku i [SEP] miÄ™dzy zdaniami.
    # Truncation=True obcina zbyt dÅ‚ugie zdania do limitu modelu (np. 512 tokenÃ³w).
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)

print("\n[2/6] Tokenizacja (zamiana sÅ‚Ã³w na numery ID)...")
tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

# EPOKA (Epoch): Przeczytanie caÅ‚ej "ksiÄ…Å¼ki" (zbioru danych) jeden raz.
# Epoch 1.0 oznacza, Å¼e model przejrzaÅ‚ wszystkie przykÅ‚ady dokÅ‚adnie raz.

# --- KLUCZOWE ROZRÃ“Å»NIENIE: TRAIN VS VALIDATION ---
# Dlaczego dzielimy dane? WyobraÅº sobie, Å¼e uczysz siÄ™ do egzaminu z matematyki.

# 1. ZbiÃ³r TRENINGOWY (train): To Twoje ZADANIA DOMOWE.
# Tu model widzi zarÃ³wno pytania, jak i poprawne odpowiedzi. Na ich podstawie model
# krÄ™ci swoimi "pokrÄ™tÅ‚ami" (wagami), Å¼eby zminimalizowaÄ‡ bÅ‚Ä…d.
# KIEDY UÅ»YWAMY: Zawsze podczas fazy wÅ‚aÅ›ciwego uczenia (trainer.train()).
tokenized_datasets["train"] = tokenized_datasets["train"].shuffle(seed=42).select(range(200))

# 2. ZbiÃ³r WALIDACYJNY (validation): To TwÃ³j EGZAMIN PRÃ“BNY.
# Model dostaje pytania, ale NIE widzi odpowiedzi podczas "rozwiÄ…zywania". My sprawdzamy
# jego odpowiedzi dopiero po fakcie. Model NIGDY nie poprawia swoich wag na podstawie
# tego zbioru â€“ on sÅ‚uÅ¼y tylko nam, Å¼eby sprawdziÄ‡, czy model siÄ™ uczy zasad, czy tylko
# kuje przykÅ‚ady na pamiÄ™Ä‡.
# KIEDY UÅ»YWAMY: Podczas treningu, zazwyczaj po kaÅ¼dej epoce, Å¼eby monitorowaÄ‡ postÄ™py.
# DLACZEGO TO POTRZEBNE? Bez walidacji nie wiedzielibyÅ›my, czy model nie wpada w
# OVERFITTING (przeuczenie). To sytuacja, w ktÃ³rej model na zadaniach domowych ma 100%
# skutecznoÅ›ci, ale na nowym pytaniu, ktÃ³rego wczeÅ›niej nie widziaÅ‚, caÅ‚kowicie polega.
tokenized_datasets["validation"] = tokenized_datasets["validation"].select(range(50))

# DATA COLLATOR: WyrÃ³wnuje dÅ‚ugoÅ›Ä‡ zdaÅ„ w paczce (batchu) dodajÄ…c zera (padding).
# Modele wymagajÄ…, aby dane w jednej paczce (batch) miaÅ‚y identyczny wymiar.
# DYNAMIC PREDDING: Zmniejsza obciÄ…Å¼enie obliczeniowe poprzez dopeÅ‚nianie tylko do
# maksymalnej dÅ‚ugoÅ›ci w obrÄ™bie kaÅ¼dej partii (batch), a nie caÅ‚ego zbioru.
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# ==============================================================================
# 2. MODEL I WAGI (DODAWANIE NOWEJ GÅOWICY)
# ==============================================================================
print("\n[3/6] Åadowanie modelu i instalacja nowej 'GÅ‚owicy' klasyfikatora...")
# KLUCZOWY MOMENT: Odcinamy oryginalnÄ… gÅ‚owÄ™ BERT-a (do przewidywania sÅ‚Ã³w)
# i "przyszywamy" nowÄ…, klasyfikacyjnÄ… gÅ‚owÄ™ z 2 wyjÅ›ciami (TAK/NIE).
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

# WAGI (Weights): To miliony "pokrÄ™teÅ‚" (liczb) wewnÄ…trz modelu. Trening to krÄ™cenie nimi.
# KaÅ¼da waga decyduje, jak mocno dany sygnaÅ‚ wpÅ‚ywa na wynik koÅ„cowy.
# Wagi w "mÃ³zgu" sÄ… ustawione przez Google, ale w nowej gÅ‚owie sÄ… na razie LOSOWE.
weights_before = model.classifier.weight.data[0][:5].clone()
print(f"ğŸ‘‰ Wagi nowej gÅ‚owy PRZED treningiem (losowe): {weights_before}")

# ==============================================================================
# 3. TEST MODELU PRZED TRENINGIEM (Zgadujemy!)
# ==============================================================================
print("\n[3.5] TEST PRZED TRENINGIEM (Logity i Softmax):")
# Wyzwanie dla synonimÃ³w: czy model "poczuje" podobieÅ„stwo bez nauki?
z1 = "Pawel is here"
z2 = "Pawel is present"

# Przygotowanie danych do rÄ™cznego testu matematycznego
inputs = tokenizer(z1, z2, return_tensors="pt")

# torch.inference_mode() â€“ Jeszcze szybszy tryb "tylko do odczytu" niÅ¼ no_grad.
# CaÅ‚kowicie izoluje model od mechanizmÃ³w treningowych dla maksymalnej wydajnoÅ›ci CPU.

with torch.inference_mode():
    outputs_pre = model(**inputs)
    # LOGITY: Surowe punkty z modelu (np. [-1.2, 0.5]). Nie sumujÄ… siÄ™ do 100%.
    # SÄ… to surowe wyniki zwracane przez ostatniÄ… warstwÄ™ modelu przed Softmaxem.
    logits_pre = outputs_pre.logits

# SOFTMAX: Funkcja, ktÃ³ra zamienia surowe punkty (logity) na procenty (0-100%).
# W matematyce: przeksztaÅ‚ca wektor liczb na wektor prawdopodobieÅ„stw, ktÃ³re sumujÄ… siÄ™ do 1.
probs_pre = F.softmax(logits_pre, dim=-1)
print(f"ğŸ‘‰ Zdanie A: {z1} | Zdanie B: {z2}")
print(f"ğŸ‘‰ Surowe logity PRZED naukÄ…: {logits_pre}")
print(f"ğŸ‘‰ PewnoÅ›Ä‡ PRZED naukÄ… (Softmax): {probs_pre[0][1].item():.2%}")

# ==============================================================================
# 4. METRYKI, GRADIENTY I LOSS (Zasady oceniania)
# ==============================================================================
# TA FUNKCJA TO "EGZAMINATOR". OkreÅ›la, jak model bÄ™dzie oceniany podczas nauki.
def compute_metrics(eval_preds):
    # EWALUACJA (Evaluation): Aby oceniÄ‡ wydajnoÅ›Ä‡ modelu w sposÃ³b zrozumiaÅ‚y dla czÅ‚owieka,
    # potrzebujemy metryk, a nie tylko samej straty (loss).
    # Biblioteka 'evaluate' dostarcza prosty sposÃ³b na Å‚adowanie metryk (np. GLUE MRPC).
    metric = evaluate.load("glue", "mrpc")

    # eval_preds to paczka zawierajÄ…ca:
    # 1. Logity (co model "myÅ›li" - surowe liczby)
    # 2. Labels (jaka jest prawda - etykiety 0/1)
    logits, labels = eval_preds

    # LOSS (Strata): Matematyczna miara bÅ‚Ä™du. JeÅ›li spada, model lepiej rozumie dane.
    # WyobraÅº sobie Loss jako odlegÅ‚oÅ›Ä‡ od celu â€“ im mniejszy Loss, tym bliÅ¼ej jesteÅ›my prawdy.
    # GRADIENT: Instrukcja, w ktÃ³rÄ… stronÄ™ krÄ™ciÄ‡ wagÄ…, aby LOSS malaÅ‚.
    # Gradient to matematyczna "strzaÅ‚ka" mÃ³wiÄ…ca: "Zmniejsz tÄ™ wagÄ™ o 0.01, aby byÄ‡ bliÅ¼ej wyniku".
    # GRAD_NORM: SiÅ‚a tej instrukcji (im wiÄ™kszy, tym gwaÅ‚towniejsza zmiana wag).

    # PREDICTIONS: To ostateczny "strzaÅ‚" modelu (odpowiedÅº na egzaminie).
    # Wybieramy indeks (0 lub 1), ktÃ³ry otrzymaÅ‚ najwiÄ™cej punktÃ³w w logitach.
    # ARGMAX: Wybieramy indeks o najwyÅ¼szej wartoÅ›ci dla kaÅ¼dej prÃ³bki,
    # aby przeksztaÅ‚ciÄ‡ logity w konkretne klasy (0 lub 1).
    # PrzykÅ‚ad: jeÅ›li logity to [-2.5, 3.1], argmax wybierze indeks "1" (klasa pozytywna).
    predictions = np.argmax(logits, axis=-1)

    # LABELS: To "klucz odpowiedzi" (prawdziwe etykiety ze zbioru danych).
    # Nauczyciel (metric) porÃ³wnuje predictions z labels.
    # Wynik to sÅ‚ownik zawierajÄ…cy Accuracy (dokÅ‚adnoÅ›Ä‡) oraz F1 Score (Å›rednia precyzji i peÅ‚noÅ›ci).
    # Accuracy mÃ³wi: "Ile razy trafiÅ‚eÅ›?". F1 mÃ³wi: "Jak dobrze radzisz sobie z obiema klasami?".
    return metric.compute(predictions=predictions, references=labels)

# ==============================================================================
# 5. KONFIGURACJA TRENINGU (Zoptymalizowana pod Intel Ultra 7 + Zaawansowane funkcje)
# ==============================================================================
# TrainingArguments to "centrum sterowania" procesem nauki. To tutaj decydujemy o strategii.
training_args = TrainingArguments(
    output_dir="./test-trainer-cpu",
    # UÅ¼ywamy CPU, bo GPU zawiesza laptopa przy obliczeniach AI.
    use_cpu=True,

    # --- ZAAWANSOWANE FUNKCJE TRENINGOWE (ADVANCED FEATURES) ---

    # EVALUATION STRATEGY: Pozwala kontrolowaÄ‡ czÄ™stotliwoÅ›Ä‡ przeprowadzania testÃ³w.
    # "epoch" oznacza sprawdzian (eval) po kaÅ¼dej peÅ‚nej epoce (przeczytaniu caÅ‚ych danych).
    # DziÄ™ki temu po kaÅ¼dej epoce zobaczymy, czy model staje siÄ™ mÄ…drzejszy.
    eval_strategy="epoch",

    # LEARNING RATE SCHEDULER: Model domyÅ›lnie zmniejsza "dÅ‚ugoÅ›Ä‡ kroku" (LR) wraz z treningiem.
    # "cosine" (kosinusoidalny) to zaawansowany sposÃ³b: najpierw model uczy siÄ™ szybko,
    # a potem coraz delikatniej "cyzeluje" wagi, co zapobiega psuciu wynikÃ³w na koniec.
    # Metafora: Na poczÄ…tku biegniesz w stronÄ™ celu, a na koÅ„cu robisz maÅ‚e, precyzyjne kroczki.
    lr_scheduler_type="cosine",

    # MIXED PRECISION (fp16): Pozwala na obliczenia na liczbach 16-bitowych zamiast 32-bitowych.
    # UWAGA: Na CPU zazwyczaj zostawiamy False, ale na nowszych GPU ustawienie fp16=True
    # dramatycznie przyspiesza trening i oszczÄ™dza poÅ‚owÄ™ pamiÄ™ci VRAM.
    # Mniejsza precyzja (mniej cyfr po przecinku) pozwala "upchnÄ…Ä‡" wiÄ™cej obliczeÅ„ naraz.
    fp16=False,

    # GRADIENT ACCUMULATION: Technika dla osÃ³b z maÅ‚Ä… iloÅ›ciÄ… pamiÄ™ci.
    # JeÅ›li ustawisz gradient_accumulation_steps=4 i batch_size=4, model zachowa siÄ™ tak,
    # jakby trenowaÅ‚ na paczce o rozmiarze 16, ale "pogryzie" jÄ… na mniejsze kawaÅ‚ki po 4.
    # DziÄ™ki temu oszczÄ™dzamy pamiÄ™Ä‡ RAM, symulujÄ…c pracÄ™ na potÄ™Å¼nym sprzÄ™cie.
    gradient_accumulation_steps=1,

    num_train_epochs=3,  # Model przeczyta 200 zdaÅ„ 3 razy (lepsza stabilnoÅ›Ä‡).
    # LEARNING_RATE: To "pewnoÅ›Ä‡ siebie" modelu. 2e-5 to bardzo maÅ‚a wartoÅ›Ä‡ (0.00002).
    # MaÅ‚e kroki zapobiegajÄ… "przeskoczeniu" idealnego ustawienia wag (tzw. overshooting).
    learning_rate=2e-5,  # "DÅ‚ugoÅ›Ä‡ kroku" (jak mocno gradient zmienia wagi).
    per_device_train_batch_size=4,  # Wykorzystujemy 14 rdzeni Twojego procesora.
    weight_decay=0.01,  # "Hamulec": zapobiega przypisywaniu ogromnych wag sÅ‚owom.
    # WEIGHT DECAY to kara za zbyt duÅ¼e wagi. Zapobiega sytuacji, w ktÃ³rej model skupia siÄ™
    # obsesyjnie na jednym sÅ‚owie (np. "the") ignorujÄ…c resztÄ™ kontekstu.
    logging_steps=5,  # Co 5 paczek wypisz stan w konsoli.
)

# ==============================================================================
# 6. TWORZENIE TRAINERA (DYRYGENT PROCESU)
# ==============================================================================
# Trainer Å‚Ä…czy model, dane, parametry i metryki w jednÄ… maszynÄ™ treningowÄ….
# WyobraÅº sobie Trainera jako dyrygenta orkiestry â€“ pilnuje, aby dane pÅ‚ynÄ™Å‚y do modelu,
# metryki byÅ‚y liczone, a wagi aktualizowane w odpowiednim momencie.
trainer = Trainer(
    model=model,                 # Nasz BERT z nowÄ… gÅ‚owicÄ….
    args=training_args,          # Wszystkie ustawienia z punktu 5.
    train_dataset=tokenized_datasets["train"],      # MateriaÅ‚y do nauki.
    eval_dataset=tokenized_datasets["validation"], # MateriaÅ‚y do sprawdzianu.
    data_collator=data_collator, # Maszyna do wyrÃ³wnywania dÅ‚ugoÅ›ci zdaÅ„ (padding).
    processing_class=tokenizer,  # Nasz tÅ‚umacz tekstu na liczby.
    compute_metrics=compute_metrics, # Nasz egzaminator z punktu 4.
)

# ==============================================================================
# 7. TRENING I ANALIZA ZMIAN W "MÃ“ZGU"
# ==============================================================================
print("\n[4/6] Start Fine-tuningu (Trening nowej gÅ‚owy na Intel Ultra 7)...")
# LOSS (Strata) powinna spadaÄ‡ z kaÅ¼dym krokiem.
# Podczas trainer.train() model wykonuje pÄ™tlÄ™ treningowÄ…:
# 1. Przekazuje dane przez model (Forward pass) - "Czytanie pytania"
# 2. Oblicza bÅ‚Ä…d (Loss) - "Sprawdzanie bÅ‚Ä™du"
# 3. Oblicza gradienty (Backward pass) - "Szukanie przyczyny bÅ‚Ä™du"
# 4. Aktualizuje pokrÄ™tÅ‚a (Optimizer step) - "Poprawa wiedzy (zmiana wag)"
trainer.train()

print("\n[5/6] Sprawdzanie zmian w 'mÃ³zgu' modelu...")
weights_after = model.classifier.weight.data[0][:5].clone()
print(f"ğŸ‘‰ Wagi przed: {weights_before}")
print(f"ğŸ‘‰ Wagi po:    {weights_after}")

# RÃ“Å»NICA: Pokazuje o ile fizycznie przesunÄ™Å‚y siÄ™ wagi pod wpÅ‚ywem uczenia.
diff = weights_after - weights_before
print(f"ğŸ‘‰ RÃ³Å¼nica (fizyczny efekt nauki): {diff}")

# ==============================================================================
# 8. TEST PRAKTYCZNY PO TRENINGU (SYNONYM TEST)
# ==============================================================================
print("\n[6/6] TEST PO TRENINGU (Analiza synonimÃ³w):")
# Ponownie uÅ¼ywamy inference_mode dla najszybszego sprawdzenia wyniku.
with torch.inference_mode():
    outputs_post = model(**inputs)
    # Ponownie zamieniamy logity na % po treningu za pomocÄ… Softmaxu
    probs_post = F.softmax(outputs_post.logits, dim=-1)
    confidence = probs_post[0][1].item()

print(f"ğŸ‘‰ Zdanie A: {z1} | Zdanie B: {z2}")
print(f"ğŸ‘‰ Wynik PRZED naukÄ…: {probs_pre[0][1].item():.2%}")
print(f"ğŸ‘‰ Wynik PO nauce:    {confidence:.2%}")

# --- ANALIZA TECHNICZNA DLA KOLEGI (WHY THIS MATTERS) ---
# 1. SEMANTIC SIMILARITY: Model musiaÅ‚ wykazaÄ‡ siÄ™ wiedzÄ… z pre-trainingu,
#    Å¼eby wiedzieÄ‡, Å¼e "here" i "present" to w tym kontekÅ›cie synonimy.
#
# 2. ROLE OF ATTENTION: Twoje 144 gÅ‚owy uwagi analizujÄ… kontekst sÅ‚owa "Pawel".
#    W obu zdaniach Pawel peÅ‚ni tÄ™ samÄ… rolÄ™ (podmiot), co pomaga modelowi.
#
# 3. CPU EFFICIENCY: Trening trwaÅ‚ krÃ³tko, bo TwÃ³j Ultra 7 Å›wietnie
#    radzi sobie z matematykÄ… macierzowÄ… dziÄ™ki instrukcjom AVX/AMX.

# ==============================================================================
# 9. ZAPISYWANIE MODELU NA DYSKU
# ==============================================================================
# Zapisujemy wagi modelu i sÅ‚ownik tokenizera do folderu.
trainer.save_model("./fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy")
tokenizer.save_pretrained("./fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy")
print("\nModel zapisany w './fine_tuning_a_model_with_the_trainer_api/moj_model_synonimy'!")